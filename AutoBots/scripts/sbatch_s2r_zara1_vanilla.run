#!/bin/bash

#SBATCH --chdir /home/yueliu/vita/SocialCausality/AutoBots
#SBATCH --output slurm/s2r-zara1-%j.out

#SBATCH --cpus-per-task 20
#SBATCH --mem 90G
#SBATCH --time 6:00:00
#SBATCH --gres=gpu:1
#SBATCH --partition=gpu
#SBATCH --qos=gpu

echo "Start: $(date)"

###################################

module load gcc/11.3.0 python/3.10.4
source /home/yueliu/vita/SocialCausality/venvsocialcausal/bin/activate

###################################

SAVEDIR=/scratch/izar/yueliu/socialcausality/s2r

DATASET=zara1

REALDIR=./datasets/eth-ucy/processed_6/${DATASET}_cheat/
SIMDIR=/work/vita/ahmad_rh/synth_v2_0.5/

DATASIZE=1.0
VALLARGE=1000000

SIMCAUSAL=0.0
for SIMPRED in 0.0 0.1 1.0 10.0; do
    python train.py \
        --exp-id s2r_${DATASET}_${DATASIZE}_causal_${SIMCAUSAL}_predict_${SIMPRED} \
        --seed 1 \
        --dataset s2r \
        --dataset-path ${REALDIR} \
        --model-type Autobot-Ego \
        --num-modes 1 \
        --hidden-size 128 \
        --num-encoder-layers 1 \
        --num-decoder-layers 1 \
        --dropout 0.0 \
        --entropy-weight 40.0 \
        --kl-weight 20.0 \
        --use-FDEADE-aux-loss True \
        --tx-hidden-size 384 \
        --batch-size 64 \
        --num-epochs $(echo "150/$DATASIZE" | bc) \
        --learning-rate 0.00075 \
        --learning-rate-sched $(echo "10/$DATASIZE" | bc) $(echo "20/$DATASIZE" | bc) $(echo "30/$DATASIZE" | bc) $(echo "40/$DATASIZE" | bc) $(echo "50/$DATASIZE" | bc) \
        --save-every $VALLARGE\
        --val-every 1 \
        --low_data $DATASIZE\
        --save_step_start $VALLARGE\
        --save_step_end $VALLARGE\
        --save_every_ckp $VALLARGE \
        --dataset-path-real ${REALDIR} \
        --dataset-path-synth ${SIMDIR} \
        --contrastive-weight 1000 \
        --save-dir $SAVEDIR \
        --batch-size-cl 64 \
        --s2r-causal ${SIMCAUSAL} \
        --s2r-predict ${SIMPRED} &
done

wait
echo "End: $(date)"